{"id":"vc-1","title":"Implement AI Code Review Sweep (rare patterns detector)","description":"Implement AI-powered code review that scans random file samples for non-obvious issues that agents miss during focused work.\n\nParent epic: vc-14\nDepends on: [deleted:vc-205] (scheduling)","design":"Philosophy (encoded):\n'Coding agents focus on their assigned task and miss issues outside \ntheir scope. Regular sweeps catch: inefficiencies, subtle bugs, poor \npatterns, missing best practices, and unnamed anti-patterns.'\n\nExamples to catch:\n- String concatenation in loops\n- Files/resources not being closed  \n- Race conditions\n- Inefficient algorithms (O(n²) where O(n) possible)\n- Copy-paste bugs (similar code with subtle differences)\n- Missing error handling\n- Hardcoded values that should be configurable\n- Public APIs without documentation\n- Test gaps for edge cases\n\nImplementation:\n\n1. Sample strategy:\n   - Daily: Review 5-10 random files\n   - Weighted toward recent changes (70% recent, 30% old)\n   - Exclude: generated files, vendor/, test fixtures\n   \n2. Build AI prompt for each file:\n   Philosophy: '...'\n   Context:\n   - File purpose (inferred from package/name)\n   - Recent changes (if any)\n   - Related files (if known)\n   \n   Task: Review this code for issues that would be obvious to an \n   experienced developer but might be missed during focused task work.\n   \n   Look for:\n   - Inefficiencies (algorithmic, resource usage)\n   - Subtle bugs (race conditions, off-by-one, copy-paste)\n   - Poor patterns (coupling, complexity, duplication)\n   - Missing best practices (error handling, docs, tests)\n   - Unnamed anti-patterns (things that 'feel wrong')\n   \n   File: [full file content]\n   \n   Return JSON for each issue found (0-3 issues per file):\n   {\n     'issues': [\n       {\n         'type': 'efficiency' | 'bug' | 'pattern' | 'best_practice' | 'other',\n         'severity': 'low' | 'medium' | 'high',\n         'location': 'file.go:45-67',\n         'title': 'Short description',\n         'description': 'Detailed explanation',\n         'suggestion': 'How to fix',\n         'priority': 'P0' | 'P1' | 'P2' | 'P3'\n       }\n     ]\n   }\n\n3. File issues:\n   - One issue per problem found\n   - Include AI's reasoning and suggestion\n   - Tag with 'code-review-sweep' label\n   - Priority as suggested by AI\n\n4. Learning:\n   - Track common patterns found\n   - Adjust sample strategy to focus on problem areas\n   - Build allowlist for false positives\n\nSampling Configuration:\n\ndaily_sample_size: 10\nrecent_change_weight: 0.7  # 70% from recently changed files\nmax_file_size: 1000        # Skip very large files (expensive)\nexclude_patterns:\n  - '*.pb.go'\n  - 'vendor/*'\n  - '*_test.go'  # Separate test review\n\nCost: Very High (10 AI calls per day, each 2-5K tokens)\nSchedule: Daily, 10 files\nBudget: ~-5/day at current AI pricing\n\nQuality Control:\n- Track false positive rate\n- If \u003e30% false positives, tune prompts\n- Humans can mark issues as 'not-a-problem'\n- Learn from feedback","acceptance_criteria":"1. Samples random files weighted by recency\n2. Excludes generated code and large files\n3. Builds detailed review prompt for each file\n4. AI identifies 0-3 issues per file\n5. Files specific issues with AI reasoning\n6. Tags issues with 'code-review-sweep' label  \n7. Tracks false positive rate\n8. Respects daily budget limits","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.14228-07:00","dependencies":[{"issue_id":"vc-1","depends_on_id":"vc-14","type":"parent-child","created_at":"2025-10-21T12:17:50.165381-07:00","created_by":"import"}]}
{"id":"vc-10","title":"Recursive review trigger - significant changes trigger re-analysis","description":"When a fix or test issue completes (discovered from code review/test analysis), check if the changes are significant and trigger another review cycle.\n\nThis implements the 'recursive review' concept from vc-21:\n- Worker fixes issue A (which was filed by code review analyzer)\n- Changes are committed\n- AI checks: are these changes significant enough to warrant another review?\n- If yes: trigger code quality analysis again\n- This continues until changes are trivial/stable\n\nPrevents infinite loops while ensuring quality. Key to autonomous operation.","design":"After processing results for any issue that was discovered-from another issue:\n\n1. Check issue.discovered_from dependency type\n2. If found, get the git diff for this completion\n3. Use Haiku to decide: 'Are these changes significant enough to re-analyze?'\n4. Haiku considers:\n   - Lines changed\n   - Semantic significance (new logic vs formatting)\n   - Risk level (critical paths vs minor fixes)\n5. If significant: trigger code quality analyzer again on parent issue\n\nThreshold: ~70% confidence to trigger re-analysis.\nPrevents cycles: max depth = 3 review levels.","acceptance_criteria":"- Detects when fix/test issues complete\n- AI decides if changes warrant re-analysis (not heuristics)\n- Triggers code quality analyzer recursively\n- Prevents infinite loops (max depth limit)\n- Works seamlessly with existing workflow\n- Logged clearly for transparency","notes":"Deferred - speculative optimization for a problem we haven't proven exists yet. Wait for empirical data from dogfooding to see if fixes commonly introduce new issues that warrant recursive analysis. YAGNI principle - the max depth limit suggests pre-solving a hypothetical problem. Normal workflow (subsequent missions or PR review) can catch issues in fixes.","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.142711-07:00","dependencies":[{"issue_id":"vc-10","depends_on_id":"vc-21","type":"parent-child","created_at":"2025-10-21T12:17:50.197457-07:00","created_by":"import"}]}
{"id":"vc-11","title":"internal/repl/conversation","description":"## Health Monitor Finding\n\n**Monitor:** file_size_monitor\n**Category:** file_size\n**Severity:** medium\n\n## Issue\n\ninternal/repl/conversation.go (1252 lines): Appears to handle conversation state management, message handling, history tracking, and possibly UI/display logic\n\n## Location\n\nFile: `internal/repl/conversation.go`\n\n## Evidence\n\n- Line count: 1252\n- Standard deviations above mean: 3.5\n- Issue: Appears to handle conversation state management, message handling, history tracking, and possibly UI/display logic\n- Suggested split: Split into conversation_state.go (state management), conversation_history.go (history operations), conversation_handler.go (message processing), conversation_display.go (rendering/UI)\n\n## Philosophy\n\nFiles should be focused on a single responsibility. Oversized files often indicate missing abstractions or unclear boundaries.\n","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.132654-07:00","labels":["file_size","health","severity:medium"]}
{"id":"vc-12","title":"Add test for NewCruftDetector error path","description":"NewCruftDetector has 75% test coverage because the error path (filepath.Abs failure) is not tested.\n\nLocation: cruft_detector.go:38-40\n\nCurrent code:\n```go\nabsPath, err := filepath.Abs(rootPath)\nif err != nil {\n    return nil, fmt.Errorf(\"invalid root path %q: %w\", rootPath, err)\n}\n```\n\nChallenge: filepath.Abs is very forgiving and rarely fails in practice (even for paths like \"../../../\" or \".\"). It's hard to trigger the error path in a platform-independent way.\n\nSimilar issue exists in FileSizeMonitor (also 75% coverage).","design":"Options:\n\n1. **Accept the gap**: Document that error path is defensive programming\n   - filepath.Abs rarely fails\n   - Error path is trivial (just wrapping error)\n   - 75% is acceptable for constructors\n\n2. **Test with platform-specific invalid paths**:\n   ```go\n   func TestNewCruftDetector_InvalidPath(t *testing.T) {\n       // This is platform-dependent and may not work everywhere\n       _, err := NewCruftDetector(\"\\x00invalid\", nil)\n       // May or may not fail depending on OS\n   }\n   ```\n\n3. **Mock filepath.Abs** (over-engineered for this case)\n\nRecommend: Option 1 (accept the gap)","acceptance_criteria":"1. Document why error path is not tested\n2. Add comment in code explaining filepath.Abs behavior\n3. OR: Add platform-specific test if possible\n4. Update coverage target to allow 75% for constructors\n5. Document testing strategy in test file","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.13291-07:00"}
{"id":"vc-13","title":"Add debug logging for skipped files in health monitors","description":"Both FileSizeMonitor and CruftDetector silently skip files when filepath.Rel fails. This is defensive programming (the error should never happen since path is validated), but makes debugging harder if it does occur.\n\nAffected locations:\n- cruft_detector.go:173-176\n- filesize.go:201-206\n\nImpact: Very low (edge case), but could hide configuration issues.\n\nCurrent code:\n```go\nrelPath, err := filepath.Rel(d.RootPath, path)\nif err != nil {\n    return nil  // Silent skip\n}\n```","design":"Add structured logging (when logging framework exists):\n\n```go\nrelPath, err := filepath.Rel(d.RootPath, path)\nif err != nil {\n    // TODO: Replace with proper logger when available\n    // For now, could use fmt.Fprintf(os.Stderr) for debugging\n    // logger.Debug(\"skipping file: cannot compute relative path\",\n    //     \"file\", path, \"root\", d.RootPath, \"error\", err)\n    return nil\n}\n```\n\nNote: Depends on VC having a logging framework. Defer until then?\nAlternative: Add comment explaining why skip is safe.","acceptance_criteria":"1. Add comment explaining why silent skip is safe\n2. Add TODO for logging when framework exists\n3. OR: Add debug logging if framework available\n4. Document in code review or design docs\n5. No functional changes (logging only)","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.133143-07:00"}
{"id":"vc-14","title":"Code Health Monitoring System","description":"Build AI-powered code health monitoring to detect accumulating technical debt that agents miss during focused task execution. Monitors detect hysteresis issues (file bloat, cruft, duplication, complexity) using ZFC-compliant AI judgments rather than hardcoded thresholds.","design":"Architecture:\n- Monitors collect facts (metrics, distributions, outliers) not judgments\n- Encode timeless philosophy, not brittle thresholds\n- AI evaluates using: philosophy + codebase context + late-2025 guidance\n- Monitors run on schedules (time-based, event-based, hybrid)\n- File grouped issues for discovered problems\n\nKey Principle: ZFC Compliance\n- NO hardcoded thresholds (they become obsolete)\n- YES timeless principles (readability, DRY, single responsibility)\n- Provide current context for AI to judge adaptively\n\nMonitor Types:\n1. Static Analysis (cheap): file size, cruft, lint\n2. AI-Based (expensive): duplication, complexity, rare patterns\n3. Trend-Based: metrics over time, degradation detection\n\nIntegration Options:\n- Option A: Separate health executor (24/7 monitoring)\n- Option B: Built into main executor (runs between tasks)\n- Option C: Hybrid (quick checks in gates, slow checks separate)\n\nDeliverables:\n- Phase 1: MVP (file size, cruft, manual command)\n- Phase 2: Scheduling (automated, intelligent)\n- Phase 3: AI monitors (duplication, complexity, code review)\n- Phase 4: Trends and historical awareness","acceptance_criteria":"1. Monitors detect hysteresis issues (file bloat, cruft accumulation)\n2. All monitors are ZFC-compliant (no hardcoded thresholds)\n3. Monitors file specific, actionable issues\n4. System runs automatically on appropriate schedules\n5. Cost-effective (cheap checks frequent, expensive checks rare)\n6. Monitors adapt to codebase evolution","status":"open","priority":2,"issue_type":"epic","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.133387-07:00"}
{"id":"vc-15","title":"Implement Duplication Detector (AI-based)","description":"Implement AI-powered code duplication detector that identifies duplicate code blocks and suggests extractions.\n\nParent epic: vc-14\nDepends on: [deleted:vc-205] (scheduling)","design":"Philosophy (encoded):\n'DRY (Don't Repeat Yourself) reduces maintenance burden. However, some \nduplication is acceptable for clarity (test setup, simple logic, different contexts).'\n\nGuidance (late-2025):\n'0-5% duplication: Excellent\n 5-10%: Good, monitor trends\n 10-20%: Review largest blocks\n \u003e20%: Likely systematic issues'\n\nImplementation:\n\n1. Run static analysis:\n   - Use goclone or dupl tool\n   - Or: simple token-based duplicate detection\n   - Find duplicate blocks \u003e10 lines\n   - Calculate overall duplication percentage\n\n2. Build AI prompt with:\n   - Philosophy statement\n   - Codebase duplication percentage\n   - Top 10 largest duplicate blocks (with file locations)\n   - Guidance for late-2025\n   \n3. AI evaluates:\n   - Is overall duplication level problematic?\n   - Which specific blocks should be extracted?\n   - Which duplicates are acceptable and why?\n   - Suggested utility names and locations\n\n4. Parse AI response:\n   {\n     'overall_assessment': 'acceptable' | 'concerning' | 'problematic',\n     'reasoning': '...',\n     'duplicates_to_extract': [\n       {\n         'locations': ['file1.go:45-67', 'file2.go:123-145'],\n         'pattern': 'String truncation with UTF-8 safety',\n         'suggested_utility': 'safeTruncateString()',\n         'suggested_location': 'internal/utils/strings.go'\n       }\n     ],\n     'acceptable_duplicates': [\n       {\n         'locations': ['test1_test.go:10-15', 'test2_test.go:12-17'],\n         'reason': 'Test setup boilerplate, context-specific'\n       }\n     ]\n   }\n\n5. File issues:\n   - One issue per extraction (not grouped)\n   - Title: 'Extract duplicated X into utility'\n   - Include: locations, suggested name, justification\n\nStatic Analysis Options:\n- goclone: github.com/mibk/dupl\n- Simple approach: hash normalized tokens\n- Or: pure AI (expensive, but no tools needed)\n\nCost: High (one AI call with large context, ~10-15K tokens)\nSchedule: Every 20 issues or weekly","acceptance_criteria":"1. Runs static analysis to find duplicate code blocks\n2. Calculates overall duplication percentage\n3. Builds ZFC-compliant prompt with context\n4. AI evaluates which duplicates warrant extraction\n5. Files specific issues for each extraction\n6. Logs acceptable duplicates with reasoning\n7. Handles both exact and near-duplicates","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.143023-07:00","dependencies":[{"issue_id":"vc-15","depends_on_id":"vc-14","type":"parent-child","created_at":"2025-10-21T12:17:50.164463-07:00","created_by":"import"}]}
{"id":"vc-16","title":"Implement Complexity Monitor (AI-based)","description":"Implement AI-powered cyclomatic complexity monitor that identifies overly complex functions.\n\nParent epic: vc-14\nDepends on: [deleted:vc-205] (scheduling)","design":"Philosophy (encoded):\n'Complex functions are hard to understand, test, and maintain. Complexity \nshould be justified by inherent problem domain complexity (e.g., parsers, \nstate machines), not poor structure.'\n\nGuidance (late-2025):\n'Complexity 1-10: Simple\n Complexity 11-20: Moderate, often acceptable\n Complexity 21-50: High, review if simplifiable\n Complexity 50+: Very high, usually warrants refactoring'\n\nImplementation:\n\n1. Run static analysis:\n   - Use gocyclo or go/ast to calculate complexity\n   - Calculate per-function cyclomatic complexity\n   - Get distribution (avg, median, outliers)\n\n2. Identify candidates:\n   - Functions with complexity \u003e20 (configurable)\n   - Or: top 10 most complex functions\n   - Or: statistical outliers (\u003e2 std devs)\n\n3. Build AI prompt with:\n   - Philosophy statement\n   - Codebase complexity distribution\n   - Project type context (parser? API? CLI?)\n   - List of high-complexity functions with:\n     * Function name and location\n     * Complexity score\n     * Function signature and body\n   \n4. AI evaluates each function:\n   - Is complexity inherent to problem domain?\n   - Can it be simplified via extraction?\n   - Is it well-tested and documented despite complexity?\n   - Suggested refactoring approach\n\n5. Parse AI response:\n   {\n     'functions_to_refactor': [\n       {\n         'function': 'processInput',\n         'location': 'parser.go:145',\n         'complexity': 35,\n         'issue': 'Multiple responsibilities mixed together',\n         'approach': 'Extract validation, parsing, and error handling'\n       }\n     ],\n     'acceptable_complexity': [\n       {\n         'function': 'parseExpression',  \n         'location': 'parser.go:234',\n         'complexity': 28,\n         'justification': 'Inherent to recursive descent parsing',\n         'recommendation': 'Add more tests and inline documentation'\n       }\n     ]\n   }\n\n6. File issues:\n   - One issue per function needing simplification\n   - Include: location, complexity score, suggested approach\n   - For acceptable-but-complex: add comment or TODO\n\nStatic Analysis Tools:\n- gocyclo: github.com/fzipp/gocyclo\n- Or: go/ast custom walker\n- Or: pure AI (expensive but language-agnostic)\n\nCost: High (AI analyzes function bodies, 10-20K tokens)\nSchedule: Every 20 issues or weekly","acceptance_criteria":"1. Calculates cyclomatic complexity for all functions\n2. Identifies high-complexity outliers\n3. Builds ZFC-compliant prompt with function context\n4. AI distinguishes inherent vs avoidable complexity\n5. Files specific refactoring issues with approaches\n6. Logs justified complex functions with recommendations\n7. Includes actual function code in prompts for AI analysis","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.143266-07:00","dependencies":[{"issue_id":"vc-16","depends_on_id":"vc-14","type":"parent-child","created_at":"2025-10-21T12:17:50.164922-07:00","created_by":"import"}]}
{"id":"vc-17","title":"Agent reports success but creates no files in sandboxed environments","description":"During vc-26 dogfooding run, the agent claimed to create DOGFOODING.md and update CLAUDE.md, reporting 'status: completed' with files_modified list. However, git status in the sandbox showed no changes - working tree clean. This is the same pattern seen in vc-9. The agent gets through the entire execution but the files are never actually written to disk.","design":"Root cause appears to be amp bypass flags (--skip-user-permission-prompts, --force-permission-grant) not working properly in sandboxed environments. The flags work in parent repo but fail when agent runs in .sandboxes/mission-X. Need to investigate: 1) Are bypass flags being passed to amp in sandbox? 2) Is amp respecting the flags? 3) Are there sandbox-specific permission restrictions? 4) Check amp logs in sandbox for permission denials.","acceptance_criteria":"Agent successfully writes files in sandboxed environments when bypass flags are set. Run vc-26 dogfooding again and verify DOGFOODING.md is created with git status showing changes.","notes":"Manually reopened - no execution claim found (orphaned status)","status":"blocked","priority":0,"issue_type":"bug","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.143454-07:00"}
{"id":"vc-18","title":"Implement Missing Utility Detector","description":"Implement AI-powered detector that identifies repeated patterns that should be extracted into reusable utilities.\n\nParent epic: vc-14\nDepends on: [deleted:vc-205] (scheduling)","design":"Philosophy (encoded):\n'When the same pattern appears multiple times, it indicates a missing \nabstraction. Extract utilities to reduce duplication and centralize \nbehavior. However, not all repetition is bad - simple operations and \ncontext-specific logic can be repeated without harm.'\n\nGuidance (late-2025):\n'Extract when:\n - Pattern appears 3+ times\n - Logic is non-trivial (\u003e5 lines)\n - Behavior should be consistent across uses\n - Pattern has clear semantic meaning\n\n Don't extract:\n - Simple operations (x == nil checks)\n - Context-dependent logic\n - Test boilerplate'\n\nImplementation:\n\n1. Pattern detection strategies:\n   \n   Strategy A: Token-based similarity\n   - Normalize code (remove variable names)\n   - Hash token sequences\n   - Find repeated sequences \u003e10 tokens\n   \n   Strategy B: AI-based (expensive but better)\n   - Feed random file samples to AI\n   - Ask AI to identify repeated patterns\n   - More accurate, catches semantic similarity\n\n2. Build AI prompt (Strategy B):\n   \n   Task: Analyze this codebase for repeated patterns that should \n   be extracted into utilities.\n   \n   Context:\n   - Existing utilities: [list from internal/utils/]\n   - Code samples: [10-20 random file snippets]\n   \n   Look for:\n   - Similar code blocks across files\n   - Operations that agents keep reinventing\n   - Common sequences that lack abstraction\n   \n   Return JSON:\n   {\n     'missing_utilities': [\n       {\n         'pattern': 'String truncation with UTF-8 safety',\n         'occurrences': [\n           'file1.go:45-52',\n           'file2.go:89-96',\n           'file3.go:123-130'\n         ],\n         'suggested_name': 'SafeTruncateString',\n         'suggested_location': 'internal/utils/strings.go',\n         'justification': 'Repeated 3 times, non-trivial logic',\n         'priority': 'P2'\n       }\n     ],\n     'acceptable_repetition': [\n       {\n         'pattern': 'nil check and return',\n         'reason': 'Too simple to warrant utility'\n       }\n     ]\n   }\n\n3. Learning from existing utilities:\n   - Scan internal/utils/, pkg/utils/\n   - Include in prompt so AI knows what exists\n   - Prevents suggesting duplicates\n\n4. Trigger conditions:\n   - Every 50 issues (significant code change)\n   - Codebase grows \u003e10%\n   - Manual: vc health check --monitor missing-utilities\n\n5. File issues:\n   - Title: 'Extract utility for [pattern]'\n   - Include: occurrences, suggested signature\n   - Priority: P2-P3 (not urgent but valuable)\n\nExample Output Issue:\n\nTitle: Extract utility for string truncation with UTF-8 safety\n\nDescription:\nThis pattern appears 3 times in the codebase:\n- utils.go:222-247\n- code_review.go:582-607 (duplicate removed)\n- deduplication.go:357-382 (duplicate removed)\n\nSuggested utility:\n\n\nLocation: internal/utils/strings.go\n\nThis will:\n- Eliminate duplication\n- Centralize string handling\n- Make UTF-8 safety consistent\n\nCost: Very High (large context, multiple files)\nSchedule: Every 50 issues or 10% growth","acceptance_criteria":"1. Detects repeated code patterns across codebase\n2. Learns existing utilities to avoid duplicates\n3. Builds prompt with code samples and existing utils\n4. AI identifies missing abstractions\n5. Suggests utility names and signatures\n6. Files issues with occurrences and justification\n7. Excludes trivial patterns (simple checks, test boilerplate)","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.143681-07:00","dependencies":[{"issue_id":"vc-18","depends_on_id":"vc-14","type":"parent-child","created_at":"2025-10-21T12:17:50.165837-07:00","created_by":"import"}]}
{"id":"vc-19","title":"Add prompt size check to CruftDetector","description":"CruftDetector builds prompts without checking size. With many files (even after limiting to 50), prompt could exceed reasonable limits.\n\nExample: 50 files × 100 chars each = 5000 chars + prompt template = ~10KB\nWith very long file paths: could be 20KB+\n\nThis relates to [deleted:vc-214] (file limit), but even with limit, should validate prompt size before sending to AI.\n\nLocation: cruft_detector.go:269-341 (buildPrompt)","design":"Add size check in buildPrompt or evaluateCruft:\n\n```go\nconst maxPromptSize = 15000 // ~4K tokens × 4 chars/token, with safety margin\n\nprompt := d.buildPrompt(filesToEvaluate)\nif len(prompt) \u003e maxPromptSize {\n    return nil, fmt.Errorf(\"prompt too large: %d chars (max %d)\", \n        len(prompt), maxPromptSize)\n}\n```\n\nOR: Build into buildPrompt return signature:\n```go\nfunc (d *CruftDetector) buildPrompt(files []cruftFile) (string, error)\n```\n\nNote: This becomes less important after [deleted:vc-214] fixes file limit.","acceptance_criteria":"1. Add maxPromptSize constant\n2. Check prompt size before sending to AI\n3. Return error if too large\n4. Add test: very long file paths trigger size check\n5. Document what happens when prompt is too large\n6. All existing tests pass","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.135314-07:00"}
{"id":"vc-2","title":"Add sandbox quota enforcement","description":"Limit the number of concurrent sandboxes to prevent disk space exhaustion and resource contention. Enforce quota before creating new sandboxes.","design":"Add sandbox quota enforcement:\n1. Add config setting: max_concurrent_sandboxes (default: 5)\n2. Before creating sandbox, count existing sandboxes in .sandboxes/\n3. If at quota, either:\n   - Wait for cleanup (if executor is actively cleaning old ones)\n   - Clean oldest failed sandbox first (LRU policy)\n   - Fail with clear error message\n4. Add disk space check: ensure N GB free before creating sandbox\n5. Add 'vc sandbox list' command to show current sandboxes and usage\n\nConsider: Weight by sandbox age (allow more recent failures to remain).","acceptance_criteria":"Executor enforces max concurrent sandboxes. Clean error message when quota hit. Disk space checked before creation. 'vc sandbox list' shows current usage.","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.130294-07:00"}
{"id":"vc-20","title":"internal/executor/executor","description":"## Health Monitor Finding\n\n**Monitor:** file_size_monitor\n**Category:** file_size\n**Severity:** medium\n\n## Issue\n\ninternal/executor/executor.go (1213 lines): Core executor likely mixing execution logic, query planning, connection management, transaction handling, and error processing\n\n## Location\n\nFile: `internal/executor/executor.go`\n\n## Evidence\n\n- Line count: 1213\n- Standard deviations above mean: 3.4\n- Issue: Core executor likely mixing execution logic, query planning, connection management, transaction handling, and error processing\n- Suggested split: Split into executor_core.go (main execution), executor_planning.go (query planning), executor_connection.go (connection pooling), executor_transaction.go (transaction management)\n\n## Philosophy\n\nFiles should be focused on a single responsibility. Oversized files often indicate missing abstractions or unclear boundaries.\n","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.135572-07:00","labels":["file_size","health","severity:medium"]}
{"id":"vc-21","title":"Engineer-in-a-Box Workflow Automation","description":"Automatic workflow filing for the complete inner loop: code → review → test → gates → docs → git. Each worker that completes triggers the next phase automatically. This is Phase 2 after MVP.","design":"**Inner Loop Workflow:**\n\nFor each ready issue:\n1. Worker implements the code\n2. Haiku decides if code review needed (based on diff analysis, NOT heuristics)\n3. If needed: Review worker files granular issues for fixes\n4. High-priority fixes surface in queue via priority + dependencies\n5. Test checker reviews test sufficiency, files issues\n6. Quality gates run (lint, etc.) - worker can fix or defer\n7. Docs/cleanup\n8. Git operations (rebase, etc.)\n\n**Key principles:**\n- Zero Framework Cognition: AI makes decisions, not heuristics\n- Granular issues: Each fix is its own issue\n- No explicit 'implement review fixes' issue - dependencies handle it\n- Recursive review: Code review that touches significant code triggers another review\n\n**Out of scope (Phase 3+):**\n- Sandbox/worktree management\n- Mission planning\n- Swarming","acceptance_criteria":"- Worker completion triggers workflow automatically\n- Haiku-based review decision (not line count heuristic)\n- Review worker files granular fix issues\n- Test checker files test improvement issues\n- Quality gates auto-run\n- Recursive review triggers correctly\n- Full inner loop completes without human intervention\n- Can complete multi-step feature end-to-end","notes":"META-EPIC: Too complex for current VC capabilities. This is what we're building TOWARD through dogfooding. VC needs this workflow complete before it can tackle work like this autonomously. Classic bootstrapping problem - we need the Engineer-in-a-Box to build the Engineer-in-a-Box.","status":"open","priority":2,"issue_type":"epic","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.135843-07:00"}
{"id":"vc-22","title":"Add validation of AI response patterns in CruftDetector","description":"CruftDetector parses AI JSON response but doesn't validate the content. AI could return invalid glob patterns or reference non-existent files, which could cause runtime errors later.\n\nPotential issues:\n- Invalid glob patterns: ***, [, etc. (would fail in filepath.Match)\n- Files not in original list (AI hallucination)\n- Empty/malformed reasoning\n\nLocation: cruft_detector.go:254-263","design":"Add validation after JSON parsing:\n\n```go\n// Validate patterns are valid globs\nfor _, pattern := range eval.PatternsToIgnore {\n    if _, err := filepath.Match(pattern, \"test\"); err != nil {\n        return nil, fmt.Errorf(\"invalid glob pattern from AI: %q: %w\", pattern, err)\n    }\n}\n\n// Optional: Validate referenced files exist in input\nfileSet := make(map[string]bool)\nfor _, f := range files {\n    fileSet[f.Path] = true\n}\nfor _, action := range eval.CruftToDelete {\n    if !fileSet[action.File] {\n        // Log warning: AI referenced file we didn't send\n    }\n}\n```","acceptance_criteria":"1. Add glob pattern validation for patterns_to_ignore\n2. Add test: invalid pattern from AI returns error\n3. Consider adding file reference validation (optional)\n4. Add test: AI references non-existent file (if implemented)\n5. All existing tests still pass","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.136298-07:00"}
{"id":"vc-23","title":"Implement metrics tracking and trend detection","description":"Implement historical metrics tracking to detect code health trends over time (improving vs degrading).\n\nParent epic: vc-14\nDepends on: vc-15, vc-16, vc-1 (AI monitors producing data)","design":"Goal: Track metrics over time to detect trends\n\nMetrics to track:\n- Average file size (lines)\n- Total LOC\n- Duplication percentage\n- Average cyclomatic complexity\n- Number of files \u003e1000 lines\n- Number of cruft files\n- Issues filed by health monitors\n- Issues closed from health monitoring\n\nStorage:\n\n.vc/metrics_history.jsonl (append-only log)\n\n{\n  'timestamp': '2025-01-15T10:30:00Z',\n  'metrics': {\n    'total_files': 247,\n    'total_loc': 65432,\n    'avg_file_size': 245,\n    'median_file_size': 180,\n    'oversized_files': 2,\n    'duplication_pct': 8.5,\n    'avg_complexity': 6.2,\n    'high_complexity_funcs': 5,\n    'cruft_files': 0,\n    'health_issues_open': 3,\n    'health_issues_closed': 12\n  }\n}\n\nTrend Detection:\n\n1. Calculate moving averages (7-day, 30-day)\n2. Detect significant changes:\n   - File size increasing \u003e20% over 30 days\n   - Duplication increasing \u003e5% over 30 days\n   - Complexity trend upward\n   \n3. Alert on degradation:\n   - File issue: 'Code health trending negative'\n   - Include: graphs, specific metrics, recommendations\n\n4. Celebrate improvements:\n   - Log positive trends\n   - Don't file issues for improvements\n\nVisualization:\n\n# Show trend report\nvc health trends\n\nOutput:\nCode Health Trends (30 days)\n\nFile Size:\n  Current avg: 245 lines\n  30-day trend: +8% ⚠️\n  Status: Growing, but acceptable\n  \nDuplication:\n  Current: 8.5%\n  30-day trend: -2% ✓\n  Status: Improving\n  \nComplexity:\n  Current avg: 6.2\n  30-day trend: +0.3 ⚠️\n  Status: Slight increase, monitor\n  \nCruft:\n  Current: 0 files ✓\n  30-day trend: Eliminated\n  Status: Clean\n\nRecommendations:\n- File size growing, review new code\n- Consider extracting utilities from recent additions\n\nAlert Thresholds:\n\n- File size +20% in 30 days: P2 issue\n- Duplication +5% in 30 days: P1 issue\n- Complexity +20% in 30 days: P2 issue\n- Cruft accumulating (\u003e10 files): P3 issue\n\nImplementation:\n1. Record metrics after each health check\n2. Calculate trends weekly\n3. File alert issues if thresholds exceeded\n4. Provide 'vc health trends' command","acceptance_criteria":"1. Records metrics to .vc/metrics_history.jsonl\n2. Calculates moving averages (7-day, 30-day)\n3. Detects significant degradation trends\n4. Files alert issues when thresholds exceeded\n5. Provides 'vc health trends' command with visualization\n6. Includes recommendations in alerts","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.143988-07:00","dependencies":[{"issue_id":"vc-23","depends_on_id":"vc-14","type":"parent-child","created_at":"2025-10-21T12:17:50.166764-07:00","created_by":"import"},{"issue_id":"vc-23","depends_on_id":"vc-15","type":"blocks","created_at":"2025-10-21T12:17:50.167007-07:00","created_by":"import"},{"issue_id":"vc-23","depends_on_id":"vc-16","type":"blocks","created_at":"2025-10-21T12:17:50.167242-07:00","created_by":"import"},{"issue_id":"vc-23","depends_on_id":"vc-1","type":"blocks","created_at":"2025-10-21T12:17:50.16748-07:00","created_by":"import"}]}
{"id":"vc-24","title":"Refactor supervisor.go to be smaller and more maintainable","description":"supervisor.go is currently 2564 lines, which is too large for a single file. This makes it hard to navigate, understand, and maintain. Split it into smaller, focused files organized by responsibility.","design":"Suggested split:\n- supervisor.go: Core Supervisor struct, constructor, main entry points\n- assessment.go: AssessCompletion, buildCompletionPrompt\n- analysis.go: AnalyzeExecution, buildAnalysisPrompt\n- recovery.go: GenerateRecoveryStrategy, buildRecoveryPrompt\n- deduplication.go: DeduplicateIssues, deduplication logic\n- translation.go: TranslateToIssue, buildTranslationPrompt\n- prompts.go: All prompt builders if they need their own file\n- retry.go: Retry logic and helpers\n- utils.go: Shared utilities like logAIUsage\n\nKeep all exported functions and types the same - this is purely an internal refactoring.","acceptance_criteria":"1. supervisor.go is under 500 lines\n2. Code is split into logical files by responsibility\n3. All tests still pass\n4. No changes to public API\n5. Code is easier to navigate and understand","notes":"Starting work in Claude Code session - refactoring supervisor.go into smaller files","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.136909-07:00"}
{"id":"vc-25","title":"Document dogfooding run #12 results and workflow observations","description":"Create comprehensive documentation for dogfooding run #12 to preserve learnings and track progress toward self-hosting.\n\nKey observations from run #12:\n- ✅ Autonomous operation worked end-to-end\n- ✅ AI assessment accurate (0.82 confidence)\n- ✅ Agent made clean surgical fix (4m22s)\n- ✅ Quality gates correctly blocked failing changes\n- ✅ Executor continued to next issue after blocking\n- ✅ Watchdog monitoring active and effective\n- ✅ Graceful shutdown working correctly\n- ❌ UNIQUE constraint failures blocked issue creation\n- ❌ Deduplication performance needs optimization\n- ⚠️ Quality gates test/lint failures need investigation\n\nThis was the first run where the agent successfully executed work but couldn't file discovered issues due to bugs.","design":"Documentation tasks:\n1. Update DOGFOODING.md with run #12 summary\n2. Update vc-26 notes with run #12 metrics\n3. Add metrics comparison table (run #11 vs #12)\n4. Document UNIQUE constraint bug impact\n5. Document quality gates behavior\n6. Update success metrics tracking\n\nInclude in documentation:\n- Execution timeline\n- AI assessment/analysis details\n- Quality gate results\n- Issues discovered (but not filed)\n- System health metrics\n- Comparison to previous runs","acceptance_criteria":"DOGFOODING.md updated with run #12 summary. vc-26 notes updated with metrics. Learnings documented for future reference.","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.144201-07:00"}
{"id":"vc-26","title":"Dogfooding Workflow: VC Self-Healing Missions","description":"Systematic dogfooding of VC to make it fix itself. Run VC missions against its own codebase, observe progress via activity feed, file discovered issues, discard sandbox state, fix high-priority issues manually, and iterate. Start with simple bugs ([deleted:vc-31], [deleted:vc-32]) and gradually increase complexity. Two successful runs completed so far.","design":"**ONGOING TRACKING ISSUE** - Remains open until VC achieves self-hosting.\n\nThis epic tracks systematic dogfooding where VC works autonomously on its own codebase for hours-to-days with minimal human intervention. Goal: Prove the architecture works and reach the point where we prefer VC over manual/Claude Code for all future development.\n\n**Full workflow documentation**: See DOGFOODING.md in repo root\n\n**Process**: 1) VC claims ready work atomically, 2) AI supervision (assess/analyze), 3) Agent executes, 4) Quality gates enforce standards, 5) File discovered issues, 6) Repeat until blocked or queue empty. Human intervenes only when: stuck \u003e30min, quality gates fail repeatedly, or key architectural decisions needed.\n\n**Safety**: No GitOps yet (intentional) - allows rollback via git reset. Enable only after 20+ missions with 90%+ gate pass rate.","acceptance_criteria":"**This issue remains OPEN until self-hosting achieved** (VC handles all development autonomously).\n\nAcceptance criteria:\n- ✅ Workflow documented (DOGFOODING.md exists)\n- ✅ Process for mission selection defined\n- ✅ Activity feed monitoring working reliably (vc tail -f, vc activity)\n- ✅ Process for issue triage defined  \n- ✅ Sandbox cleanup process defined\n- ⏳ Success metrics tracked systematically\n- ⏳ 20+ successful missions with 90%+ quality gate pass rate\n- ⏳ Proven convergence (VC finishes work, doesn't spin)\n- ⏳ GitOps enabled after stability proven\n- ⏳ Human intervention \u003c 10% of missions\n- ⏳ VC autonomously runs for 24+ hours on complex epic\n\n**Current metrics** (updated 2025-10-18):\n- Successful missions: 7\n- Quality gate pass: 6/7 (85.7%)\n- Activity feed: ✅ Working\n- GitOps: ❌ Intentionally disabled for safety\n- Auto-mission selection: ❌ Human-guided for now\n- Human intervention rate: ~40% (need to reduce to \u003c10%)","notes":"Dogfooding run #16 - 2025-10-22 (SUCCESSFUL)\n\nMODE: Code review and bug discovery\nTARGET: ZFC detector (commits 17b88c8, 84c24c7)\nDURATION: ~15 minutes\nMETHOD: Manual code inspection + compilation testing\n\nRESULTS:\n✅ Found 6 bugs through dogfooding!\n✅ All bugs fixed\n✅ All tests passing\n✅ Code ready for production\n\nBUGS DISCOVERED:\n1. Unused import: strconv (leftover after ZFC compliance changes)\n2. Undefined variable: filesScanned++ (orphaned increment)\n3. API misuse: bufio.Scanner(file) instead of bufio.NewScanner(file) (2 instances)\n4. Test cleanup: Unused variables foundCount0, foundCount1\n5. Logic bug: Supervisor validation too early (before threshold check)\n6. Test assertion: Wrong string format expectation (underscores vs spaces)\n\nKEY LEARNINGS:\n- Dogfooding works! Found real bugs before they shipped\n- Compilation testing is critical - code had build errors\n- ZFC compliance refactoring introduced regressions\n- Test failures caught logic bugs (supervisor validation order)\n\nMETRICS:\n- Bugs found: 6\n- Bugs fixed: 6\n- Lines changed: 48 (26 additions, 22 deletions)\n- Test pass rate: 100% (was 0% before fixes)\n- Time to fix: ~15 minutes\n\nNEXT STEPS:\n- Push fixes to main\n- Continue dogfooding on other components\n- Consider adding pre-commit hooks to catch compilation errors","status":"open","priority":0,"issue_type":"epic","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T10:04:40.937029-07:00"}
{"id":"vc-27","title":"Quality gates may not log completion/timeout events reliably","description":"During dogfooding run #18, quality gates started at 14:09:29 for [deleted:vc-227]. Quality gates have a 5-minute timeout configured (internal/executor/result_processor.go). However, no quality_gates_completed or quality_gates_failed event was ever logged in the activity feed.\n\nPossibilities:\n1. Quality gates hung and didn't respect 5m timeout\n2. Quality gates were interrupted by executor kill (graceful shutdown issue)\n3. Quality gates completed but event wasn't logged\n4. Quality gates are still running in orphaned process\n\nThis makes it impossible to diagnose what went wrong with quality gates.","design":"Investigation needed:\n1. Check if quality gates respect context timeout\n2. Check if quality gates log events on all code paths (success, failure, timeout, cancellation)\n3. Check graceful shutdown behavior - do gates get interrupted cleanly?\n4. Add quality_gates_timed_out event type if needed\n5. Ensure event is logged BEFORE returning from gates evaluation","acceptance_criteria":"Quality gates always emit either quality_gates_completed or quality_gates_failed event, even on timeout/cancellation. Can diagnose quality gates issues from activity feed alone.","status":"open","priority":2,"issue_type":"bug","created_at":"2025-10-21T14:31:09.811614-07:00","updated_at":"2025-10-22T00:15:23.139981-07:00"}
{"id":"vc-28","title":"Watchdog ineffective without agent progress events","description":"During dogfooding run #18, watchdog ran every 30 seconds and consistently logged 'analyzed 0 executions' because there were no agent progress events to analyze.\n\nThe agent ran for 9.5 minutes, but watchdog had no data to determine if it was stuck or working. Watchdog is designed to detect stalls and stuck agents, but it's blind without progress events.\n\nBlockers:\n- Depends on [deleted:vc-129] (agent progress events)\n- Without progress data, watchdog cannot distinguish 'slow but working' from 'stuck'\n\nImpact: Watchdog cannot fulfill its purpose without visibility into agent activity.","design":"After [deleted:vc-129] is implemented:\n1. Watchdog should analyze time_since_last_agent_event\n2. If agent spawned \u003e5m ago with zero progress events → stall alert\n3. If agent has progress events but none in \u003e2m → potential stall\n4. Confidence score based on event frequency and recency\n5. Emit watchdog_alert events when stall detected","acceptance_criteria":"With [deleted:vc-129] implemented, watchdog detects stalls and emits alerts. Without [deleted:vc-129], watchdog logs that it cannot analyze (already working).","status":"open","priority":2,"issue_type":"bug","created_at":"2025-10-21T14:31:21.523352-07:00","updated_at":"2025-10-22T00:15:23.140329-07:00"}
{"id":"vc-29","title":"Document AgentMessage JSON schema and Amp --stream-json format","description":"The AgentMessage struct in agent.go defines fields for parsing Amp's --stream-json output, but the schema is not documented.\n\nCurrent issues:\n- No documentation of which tools emit which fields\n- No documentation of field formats (tool name casing, etc.)\n- No reference to Amp version or API documentation\n- Unclear what non-tool_use event types are supported\n\nThis makes it hard to:\n- Verify the implementation is correct\n- Debug JSON parsing issues\n- Understand what data is available\n- Maintain compatibility as Amp evolves","design":"Add comprehensive godoc comment to AgentMessage struct documenting:\n\n1. JSON Schema:\n   - Event types (tool_use, system, result, etc.)\n   - Required vs optional fields\n   - Field formats and casing conventions\n\n2. Tool-to-field mapping:\n   - Read/Edit/Write: use 'file' field\n   - Bash: uses 'command' field\n   - Glob/Grep: use 'pattern' field\n   - Task: uses ? (document what fields spawning uses)\n\n3. Amp compatibility:\n   - Which Amp version introduced --stream-json\n   - Link to Amp documentation or API spec\n   - Example JSON output for common events\n\n4. Add example JSON in comments showing actual Amp output","acceptance_criteria":"- AgentMessage struct has comprehensive godoc comment\n- JSON schema is documented (required/optional fields)\n- Tool-to-field mapping is clear\n- Amp version/documentation is referenced\n- Example JSON snippets included in comments","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-21T17:40:32.441905-07:00","updated_at":"2025-10-22T00:15:23.1406-07:00"}
{"id":"vc-3","title":"Add 'bd stale' command to show orphaned claims and dead executors","description":"Need visibility into orphaned claims - issues stuck in_progress with execution_state but executor is dead/stopped. Add command to show: 1) All issues with execution_state where executor status=stopped or last_heartbeat \u003e threshold, 2) Executor instance details (when died, how long claimed), 3) Option to auto-release them. Makes manual recovery easier until auto-cleanup ([deleted:vc-122]) is implemented.","design":"Query: SELECT i.*, ei.status, ei.last_heartbeat FROM issues i JOIN issue_execution_state ies ON i.id = ies.issue_id JOIN executor_instances ei ON ies.executor_instance_id = ei.instance_id WHERE ei.status='stopped' OR ei.last_heartbeat \u003c NOW() - threshold. Add --release flag to auto-release all found issues.","acceptance_criteria":"bd stale shows orphaned claims, bd stale --release cleans them up","notes":"New beads command implementation - requires understanding beads CLI patterns and query logic. Good candidate for manual/Claude Code work.","status":"blocked","priority":1,"issue_type":"task","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.130637-07:00"}
{"id":"vc-30","title":"Verify Amp --stream-json format matches AgentMessage schema","description":"The vc-236 fix assumes Amp supports --stream-json and emits JSON matching the AgentMessage struct, but this hasn't been verified with actual Amp output.\n\nRisks:\n- Amp may not support --stream-json flag\n- JSON structure may differ from AgentMessage schema\n- Tool names may be different (capitalization, naming)\n- Fields may be named differently (file vs path, command vs cmd)\n\nThis could cause:\n- Zero progress events (like vc-231 before the fix)\n- Silent failures in convertJSONToEvent\n- Incorrect event data extraction","design":"Verification steps:\n\n1. Check Amp documentation:\n   - Does Amp support --stream-json flag?\n   - What version was it introduced?\n   - Is there API documentation or examples?\n\n2. Integration test with real Amp:\n   - Spawn Amp process with --stream-json\n   - Capture actual JSON output\n   - Parse with AgentMessage struct\n   - Verify all fields match expectations\n\n3. Document findings:\n   - Add Amp version requirements to AgentMessage godoc\n   - Link to Amp documentation or API spec\n   - Include real JSON examples in comments\n\n4. Alternative if Amp doesn't support it:\n   - File upstream issue/feature request\n   - OR implement JSON wrapper around Amp\n   - OR fall back to regex parsing for now","acceptance_criteria":"- Amp --stream-json support verified (or documented as unsupported)\n- Integration test added that spawns real Amp and parses JSON\n- AgentMessage godoc updated with Amp version requirements\n- Real JSON examples added to code comments\n- If unsupported: alternative approach documented/implemented","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-21T17:42:07.677523-07:00","updated_at":"2025-10-22T00:15:23.140858-07:00"}
{"id":"vc-31","title":"Add integration test for executor shutdown cleanup","description":"There's no integration test verifying that executor shutdown actually triggers instance cleanup (vc-133).\n\nCode review finding from vc-133.\n\nWhile unit tests for DeleteOldStoppedInstances (vc-241) test the storage layer, we need an integration test that verifies:\n- Executor registers instance on Start()\n- Executor marks instance stopped on Stop()\n- Executor deletes old stopped instances on Stop()\n- Cleanup respects maxToKeep configuration\n\nThis catches integration issues like:\n- Cleanup called with wrong parameters\n- Cleanup not called at all\n- Cleanup called at wrong time\n- Configuration not propagated correctly\n\nLocation: internal/executor/executor_test.go","design":"Add test TestExecutorShutdownCleansOldInstances:\n\n1. Setup: Create multiple old stopped instances in test database\n2. Create executor with custom cleanup config (short age, low maxToKeep)\n3. Start executor\n4. Stop executor\n5. Assert: Old instances were deleted, recent ones kept\n6. Verify: Correct number deleted based on config\n\nUse real storage (not mock) to test full integration.\nUse :memory: database for isolation.\n\nExample assertions:\n- Before shutdown: 20 old stopped instances\n- After shutdown: 10 most recent kept (maxToKeep=10)\n- Deleted count: 10","acceptance_criteria":"Integration test exists and passes. Test covers config propagation and actual cleanup on shutdown.","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-21T18:50:05.046037-07:00","updated_at":"2025-10-22T00:15:23.141228-07:00"}
{"id":"vc-32","title":"Add metrics and structured logging for instance cleanup","description":"Instance cleanup operations should emit structured events for observability, similar to event cleanup (vc-196).\n\nCode review finding from vc-133.\n\nCurrently cleanup only logs to stdout/stderr:\n- 'Cleanup: Deleted N old stopped executor instance(s)' (success)\n- 'warning: failed to cleanup old executor instances: ...' (failure)\n\nThis makes it hard to:\n- Query cleanup history\n- Track cleanup effectiveness over time\n- Debug cleanup failures\n- Monitor database bloat trends\n\nFollowing the pattern from event cleanup (vc-196), we should store structured events in agent_events table.\n\nReference: executor.go:454-463 (current logging), executor.go:1234-1282 (event cleanup pattern)","design":"Add new event type: EventTypeInstanceCleanupCompleted\n\nCreate logInstanceCleanupEvent() following the pattern from logCleanupEvent():\n\nData fields:\n- instances_deleted (total count)\n- instances_remaining (stopped instances left)\n- processing_time_ms\n- cleanup_age_seconds (threshold used)\n- max_to_keep (config value)\n- success (bool)\n- error (string, if failed)\n\nLog event in two places:\n1. Shutdown cleanup (executor.go:457)\n2. Periodic cleanup (vc-244, when implemented)\n\nAdd to events package:\n- EventTypeInstanceCleanupCompleted constant\n- InstanceCleanupCompletedData struct\n\nBenefits:\n- Query cleanup trends: 'SELECT AVG(instances_deleted) FROM agent_events WHERE type=...'\n- Debug failures: 'SELECT * FROM agent_events WHERE type=... AND success=0'\n- Monitor effectiveness over time","acceptance_criteria":"Cleanup operations emit structured events. Events queryable in agent_events table. Follows same pattern as event cleanup.","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-21T18:50:21.870861-07:00","updated_at":"2025-10-22T00:15:23.141463-07:00"}
{"id":"vc-33","title":"Make instance cleanup configurable via environment variables","description":"Instance cleanup uses hardcoded defaults (24h age, keep 10 instances) with no environment variable overrides.\n\nCode review finding from vc-133.\n\nFor consistency with event cleanup (vc-196) and deduplication (vc-151), cleanup should be configurable via environment variables.\n\nCurrent state:\n- InstanceCleanupAge: hardcoded to 24h (DefaultConfig)\n- InstanceCleanupKeep: hardcoded to 10 (DefaultConfig)\n- No way to configure without code changes\n\nUse cases for env var config:\n- Development: Aggressive cleanup (age=1h, keep=2) to test cleanup behavior\n- Production: Conservative (age=7d, keep=50) to preserve history\n- Testing: Disable cleanup entirely (age=0 means skip?)\n- CI/CD: Different settings per environment\n\nReference: config/event_retention.go (event cleanup env vars)","design":"Add environment variables following event cleanup pattern:\n\nVC_INSTANCE_CLEANUP_AGE_HOURS (default: 24)\n  - How old stopped instances must be before deletion\n  - Validation: 0-720 hours (0-30 days)\n  - 0 = disable cleanup\n\nVC_INSTANCE_CLEANUP_KEEP (default: 10)\n  - Minimum stopped instances to keep\n  - Validation: 0-1000\n  - 0 = delete all old instances\n\nImplementation:\n1. Create LoadInstanceCleanupConfigFromEnv() in internal/config/\n2. Call from cmd/vc/execute.go before creating executor\n3. Set cfg.InstanceCleanupAge and cfg.InstanceCleanupKeep\n4. Validate values and fail fast on invalid config\n\nExample:\nexport VC_INSTANCE_CLEANUP_AGE_HOURS=48\nexport VC_INSTANCE_CLEANUP_KEEP=20\nvc execute  # Uses 48h and keep 20","acceptance_criteria":"Cleanup configurable via env vars. Invalid values rejected with clear error. Documented in CLAUDE.md.","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-21T18:50:39.746805-07:00","updated_at":"2025-10-22T00:15:23.141706-07:00"}
{"id":"vc-34","title":"Implement ZFC Violation Detector","description":"AI-powered monitor that scans the codebase for Zero Framework Cognition (ZFC) violations: hardcoded thresholds, regex-based parsing, heuristic-driven logic, and other anti-patterns where AI judgment should be used instead. This detector embodies the core VC principle that all decisions should be delegated to AI.","design":"Scan for patterns:\n- Magic numbers used as thresholds (e.g., if count \u003e 10)\n- Regex patterns for semantic parsing (e.g., parsing intent from text)\n- Complex conditional logic that encodes business rules\n- String matching / keyword detection for classification\n- Hardcoded file path patterns or naming conventions\n\nAI evaluates each finding:\n- Is this a legitimate ZFC violation?\n- What's the impact (low/medium/high)?\n- Suggested refactoring approach\n- Does this encode assumptions that will become stale?\n\nFiles issues for confirmed violations with:\n- Location and code snippet\n- Why it violates ZFC\n- Impact assessment\n- Refactoring suggestion","acceptance_criteria":"1. Detects hardcoded thresholds where AI judgment should be used\n2. Identifies regex/parsing logic that encodes semantic meaning\n3. Flags heuristics that should be AI-driven decisions\n4. Produces actionable issues with refactoring guidance\n5. Avoids false positives (legitimate constants vs. decision thresholds)\n6. Cost-effective: caches results, only scans changed files incrementally","notes":"Implemented ZFC Violation Detector with the following features:\n\n✅ Core Implementation (internal/health/zfc_detector.go):\n- HealthMonitor interface implementation (Name, Philosophy, Schedule, Cost, Check)\n- Dual analysis approach: AST-based for Go files + regex-based fallback\n- Detects 5 violation types:\n  1. Magic number thresholds (e.g., if count \u003e 50)\n  2. Regex for semantic parsing (regexp.MustCompile)\n  3. String matching for classification (strings.Contains, HasPrefix, etc.)\n  4. Complex conditionals (3+ conditions encoding business rules)\n  5. Hardcoded file paths\n- AI evaluation to distinguish true violations from legitimate code\n- Configurable thresholds and exclusion patterns\n- Cost-effective: limits to 30 violations per AI call\n\n✅ Tests (internal/health/zfc_detector_test.go):\n- Interface compliance tests\n- Path validation tests\n- Detection tests for each violation type\n- Exclusion pattern tests (vendor/, _test.go, testdata/)\n- Mock AI supervisor for integration testing\n- Prompt generation tests\n\n✅ CLI Integration (cmd/vc/health.go):\n- Added 'zfc' monitor to available monitors map\n- Updated help text and examples\n- Included in default monitor run order\n\nUsage:\n  vc health check --monitor zfc          # Run ZFC detector only\n  vc health check                        # Run all monitors (includes zfc)\n  vc health check --monitor zfc --dry-run # Preview without filing issues\n\nThe detector is fully ZFC-compliant: it collects potential violations (facts) and delegates judgment to AI to avoid false positives.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-22T00:03:45.592161-07:00","updated_at":"2025-10-22T00:25:05.817722-07:00","closed_at":"2025-10-22T00:25:05.817722-07:00","dependencies":[{"issue_id":"vc-34","depends_on_id":"vc-14","type":"parent-child","created_at":"2025-10-22T00:03:50.441684-07:00","created_by":"daemon"}]}
{"id":"vc-35","title":"Implement tiered AI model strategy for cost optimization","description":"VC currently uses Sonnet 4.5 (top-tier, most expensive model) for ALL AI operations. Many operations (cruft detection, file size analysis, commit messages, git safety checks) are simple enough for Haiku, which costs ~80% less.\n\nCurrent State:\n- 13+ different AI operations all using Sonnet 4.5\n- No model selection strategy\n- No cost tracking\n\nCost Impact:\n- Conservative estimate: $34/year with weekly runs\n- Realistic at scale: $500-1000+/year with daily multi-issue usage\n- Potential savings: 27-44% with tiered strategy\n\nOperations by Complexity:\n\nHIGH (Keep Sonnet):\n- Assessment, Analysis, Code Review, Recovery\n- Planning, ZFC Detector, REPL Conversation\n\nLOW (Switch to Haiku - ~80% savings):\n- Cruft Detector, File Size Monitor\n- Commit Message Generator, Git Safety Checks\n\nMEDIUM (Test Haiku, maybe fallback):\n- Deduplication, Watchdog operations","design":"Phase 1: Add model parameter to CallAI interface\nPhase 2: Switch 3+ simple operations to Haiku (cruft, filesize, git)\nPhase 3: Environment-based config (VC_MODEL_HEALTH, etc)\nPhase 4: Cost tracking and reporting\nPhase 5: Adaptive selection with fallback","acceptance_criteria":"1. CallAI supports explicit model parameter\n2. 3+ operations using Haiku\n3. \u003c5% quality degradation\n4. Env var configuration\n5. Cost logging per operation\n6. Documentation on model selection\n7. 25%+ cost savings demonstrated","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-22T09:54:47.823003-07:00","updated_at":"2025-10-22T09:54:47.823003-07:00"}
{"id":"vc-36","title":"Quality gates run in wrong order - build should be first","description":"CRITICAL: Quality gates run in the order TEST → LINT → BUILD, but should run BUILD → TEST → LINT.\n\n**Current behavior** (internal/gates/gates.go:86-94):\n```\ngates := []struct{...}{\n    {GateTest, r.runTestGate},    // Runs first\n    {GateLint, r.runLintGate},    // Runs second  \n    {GateBuild, r.runBuildGate},  // Runs last\n}\n```\n\n**Why this is wrong:**\n1. **Tests broken code**: go test fails with compilation errors instead of test failures\n2. **Wastes time**: Runs tests/lint on code that doesn't even compile\n3. **Confusing errors**: Test failures look like test failures, not build failures\n4. **Discovered via dogfooding**: vc-26 run #16 would have caught 6 compilation errors if build ran first\n\n**Real-world impact:**\n- Dogfooding run #16 found 6 compilation errors manually\n- If quality gates ran build first, these would have been caught automatically\n- Agent might commit broken code that doesn't compile!\n\n**Example from today:**\n```\ninternal/health/zfc_detector.go:13:2: \"strconv\" imported and not used\ninternal/health/zfc_detector.go:207:3: undefined: filesScanned\ninternal/health/zfc_detector.go:418:27: cannot convert file to bufio.Scanner\n```\n\nThese are BUILD errors, but would show as test failures.\n\n**Correct order:**\n1. BUILD (fast, catches syntax/compilation errors)\n2. TEST (medium, validates logic)\n3. LINT (slow, checks style/quality)","design":"Change order in internal/gates/gates.go from:\n```go\ngates := []struct{...}{\n    {GateTest, r.runTestGate},\n    {GateLint, r.runLintGate},\n    {GateBuild, r.runBuildGate},\n}\n```\n\nTo:\n```go\ngates := []struct{...}{\n    {GateBuild, r.runBuildGate},  // First: verify it compiles\n    {GateTest, r.runTestGate},    // Second: verify logic works\n    {GateLint, r.runLintGate},    // Third: verify style/quality\n}\n```\n\nAlso consider SHORT-CIRCUITING: if build fails, don't bother running tests.\nCurrently gates.go:110 continues even after failures (\"gives comprehensive feedback\").\n\nFor BUILD failures specifically, we should probably stop immediately since tests can't run anyway.","acceptance_criteria":"1. Quality gates run in order: BUILD → TEST → LINT\n2. Build gate runs before any tests\n3. Test suite shows build errors clearly (not masked as test failures)\n4. Dogfooding catches compilation errors automatically\n5. Documentation updated to explain gate order rationale","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-10-22T11:33:45.725489-07:00","updated_at":"2025-10-22T11:38:54.754485-07:00","closed_at":"2025-10-22T11:38:54.754485-07:00"}
{"id":"vc-37","title":"Beads Library Migration","description":"Migrate VC from its own internal/storage to using Beads v0.12.0 as a library. This provides 100x performance improvement, type safety, atomic operations, and enables the mission workflow architecture.","design":"Architecture: Extension model (IntelliJ/Android Studio pattern). Beads provides core tables (issues, dependencies, labels), VC adds extension tables (vc_mission_state, vc_agent_events, vc_executor_instances). Both use same .beads/vc.db file. Type conversion between beadsTypes.Issue and vcTypes.Issue happens in wrapper layer.","acceptance_criteria":"All VC code uses Beads storage wrapper. Integration tests pass. Executor runs with Beads. Old internal/storage removed. Performance improvement verified (100x+ for core operations).","status":"open","priority":0,"issue_type":"epic","created_at":"2025-10-22T19:40:51.191973-07:00","updated_at":"2025-10-22T19:40:51.191973-07:00"}
{"id":"vc-38","title":"Add Beads v0.12.0 to go.mod","description":"","acceptance_criteria":"Beads v0.12.0 is direct dependency in go.mod","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-22T19:41:12.419383-07:00","updated_at":"2025-10-22T19:41:52.647697-07:00","closed_at":"2025-10-22T19:41:52.647697-07:00","dependencies":[{"issue_id":"vc-38","depends_on_id":"vc-37","type":"parent-child","created_at":"2025-10-22T19:41:39.042794-07:00","created_by":"daemon"}]}
{"id":"vc-39","title":"Create VCStorage wrapper (internal/storage/beads/)","description":"","acceptance_criteria":"Wrapper.go, methods.go, executor.go created. Embeds beads.Storage. Creates extension tables on init.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-22T19:41:15.383112-07:00","updated_at":"2025-10-22T19:41:52.658089-07:00","closed_at":"2025-10-22T19:41:52.658089-07:00","dependencies":[{"issue_id":"vc-39","depends_on_id":"vc-37","type":"parent-child","created_at":"2025-10-22T19:41:39.054257-07:00","created_by":"daemon"},{"issue_id":"vc-39","depends_on_id":"vc-38","type":"blocks","created_at":"2025-10-22T19:41:45.329038-07:00","created_by":"daemon"}]}
{"id":"vc-4","title":"Agent event storage CHECK constraint violation","description":"During agent execution, attempts to store agent events fail with CHECK constraint violation. The agent is trying to store an event type that's not in the whitelist. This prevents agent events from being persisted to the activity feed database.","design":"The CHECK constraint in the agent_events table validates event types against a whitelist. The error shows the full whitelist (file_modified, test_run, git_operation, build_output, lint_output, progress, error, watchdog_alert for agent events; issue_claimed, assessment_started, etc. for executor events). Need to: 1) Add logging to capture which event type is being rejected, 2) Review agent spawning code to find invalid event type, 3) Either add the missing type to whitelist OR fix agent code to use correct type, 4) Add validation earlier in the pipeline to catch invalid types before DB insert","acceptance_criteria":"All agent events store successfully without CHECK constraint errors. Activity feed shows complete execution history.","notes":"Ready for retry after run #12","status":"blocked","priority":1,"issue_type":"bug","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.130918-07:00"}
{"id":"vc-40","title":"Implement all storage.Storage interface methods","description":"","acceptance_criteria":"All methods delegate to Beads or query extension tables. Type conversion works correctly.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-22T19:41:16.616141-07:00","updated_at":"2025-10-22T19:41:52.668021-07:00","closed_at":"2025-10-22T19:41:52.668021-07:00","dependencies":[{"issue_id":"vc-40","depends_on_id":"vc-37","type":"parent-child","created_at":"2025-10-22T19:41:39.064687-07:00","created_by":"daemon"},{"issue_id":"vc-40","depends_on_id":"vc-39","type":"blocks","created_at":"2025-10-22T19:41:45.340401-07:00","created_by":"daemon"}]}
{"id":"vc-41","title":"Create integration tests for Beads wrapper","description":"","acceptance_criteria":"integration_test.go validates: create issues, missions, labels, ready work, executor instances, claim/release","status":"closed","priority":0,"issue_type":"task","created_at":"2025-10-22T19:41:17.816598-07:00","updated_at":"2025-10-22T19:41:52.678474-07:00","closed_at":"2025-10-22T19:41:52.678474-07:00","dependencies":[{"issue_id":"vc-41","depends_on_id":"vc-37","type":"parent-child","created_at":"2025-10-22T19:41:39.07502-07:00","created_by":"daemon"},{"issue_id":"vc-41","depends_on_id":"vc-40","type":"blocks","created_at":"2025-10-22T19:41:45.351286-07:00","created_by":"daemon"}]}
{"id":"vc-42","title":"Run integration tests and fix issues","description":"","acceptance_criteria":"All tests in internal/storage/beads/ pass","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-22T19:41:18.953302-07:00","updated_at":"2025-10-22T19:41:18.953302-07:00","dependencies":[{"issue_id":"vc-42","depends_on_id":"vc-37","type":"parent-child","created_at":"2025-10-22T19:41:39.085483-07:00","created_by":"daemon"},{"issue_id":"vc-42","depends_on_id":"vc-41","type":"blocks","created_at":"2025-10-22T19:41:45.361437-07:00","created_by":"daemon"}]}
{"id":"vc-43","title":"Update executor to use Beads storage","description":"","acceptance_criteria":"Executor uses beads.NewVCStorage() instead of storage.NewStorage(). Compiles and runs.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-22T19:41:20.180975-07:00","updated_at":"2025-10-22T19:41:20.180975-07:00","dependencies":[{"issue_id":"vc-43","depends_on_id":"vc-37","type":"parent-child","created_at":"2025-10-22T19:41:39.095706-07:00","created_by":"daemon"},{"issue_id":"vc-43","depends_on_id":"vc-42","type":"blocks","created_at":"2025-10-22T19:41:45.371452-07:00","created_by":"daemon"}]}
{"id":"vc-44","title":"Validate with dogfooding run","description":"","acceptance_criteria":"VC executor runs end-to-end with Beads storage. Claim/execute/analyze/gates all work.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-22T19:41:21.347848-07:00","updated_at":"2025-10-22T19:41:21.347848-07:00","dependencies":[{"issue_id":"vc-44","depends_on_id":"vc-37","type":"parent-child","created_at":"2025-10-22T19:41:39.105782-07:00","created_by":"daemon"},{"issue_id":"vc-44","depends_on_id":"vc-43","type":"blocks","created_at":"2025-10-22T19:41:45.38199-07:00","created_by":"daemon"}]}
{"id":"vc-45","title":"Remove old internal/storage implementation","description":"","acceptance_criteria":"internal/storage/sqlite/ deleted. Only Beads wrapper remains.","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-22T19:41:22.471946-07:00","updated_at":"2025-10-22T19:41:22.471946-07:00","dependencies":[{"issue_id":"vc-45","depends_on_id":"vc-37","type":"parent-child","created_at":"2025-10-22T19:41:39.116058-07:00","created_by":"daemon"},{"issue_id":"vc-45","depends_on_id":"vc-44","type":"blocks","created_at":"2025-10-22T19:41:45.392311-07:00","created_by":"daemon"}]}
{"id":"vc-46","title":"Fix ExecutionState enum mismatch in vc_issue_execution_state","description":"The vc_issue_execution_state table CHECK constraint only allows: 'pending', 'claimed', 'executing', 'analyzing', 'completed', 'failed'. But types.ExecutionState enum includes: 'assessing', 'gates', 'committing' which will be REJECTED by the constraint. This will cause runtime errors when the executor tries to set these states.","design":"Sync the CHECK constraint in vcExtensionSchema (wrapper.go:129) to match all ExecutionState constants from types/types.go:274-282. The constraint should be: CHECK(state IN ('pending', 'claimed', 'assessing', 'executing', 'analyzing', 'gates', 'committing', 'completed', 'failed'))","acceptance_criteria":"CHECK constraint includes all ExecutionState enum values. Test that all state transitions work without constraint violations.","status":"open","priority":0,"issue_type":"bug","created_at":"2025-10-22T20:06:46.831275-07:00","updated_at":"2025-10-22T20:06:46.831275-07:00","dependencies":[{"issue_id":"vc-46","depends_on_id":"vc-37","type":"blocks","created_at":"2025-10-22T20:07:07.464554-07:00","created_by":"daemon"}]}
{"id":"vc-47","title":"Fix ExecutionAttempt schema - missing 6 fields in vc_execution_history","description":"The vc_execution_history table only has 7 columns but types.ExecutionAttempt has 13 fields. Missing: AttemptNumber, Success, ExitCode, Summary, OutputSample, ErrorSample. RecordExecutionAttempt() will fail to store these fields, GetExecutionHistory() will return incomplete data.","design":"Add missing columns to vc_execution_history table: attempt_number INTEGER NOT NULL, success BOOLEAN, exit_code INTEGER, summary TEXT, output_sample TEXT (stores last 1000 lines), error_sample TEXT (stores last 1000 lines). Update executor.go:332-344 INSERT statement and executor.go:347-381 SELECT/Scan.","acceptance_criteria":"All ExecutionAttempt fields persist to database. GetExecutionHistory() returns complete ExecutionAttempt objects with all 13 fields populated.","status":"open","priority":0,"issue_type":"bug","created_at":"2025-10-22T20:06:48.274749-07:00","updated_at":"2025-10-22T20:06:48.274749-07:00","dependencies":[{"issue_id":"vc-47","depends_on_id":"vc-37","type":"blocks","created_at":"2025-10-22T20:07:07.47689-07:00","created_by":"daemon"}]}
{"id":"vc-48","title":"Fix StoreAgentEvent JSON marshaling - data loss bug","description":"StoreAgentEvent() uses fmt.Sprintf(\"%v\", event.Data) instead of json.Marshal(). This produces garbage like '\u0026{field1 field2}' instead of valid JSON. All agent event data is silently corrupted in the database.","design":"In wrapper.go:162-180, replace fmt.Sprintf with json.Marshal: jsonBytes, err := json.Marshal(event.Data); if err \\!= nil { return fmt.Errorf(\"failed to marshal event data: %w\", err) }; dataJSON = string(jsonBytes). Also add corresponding json.Unmarshal in GetAgentEventsByIssue and GetRecentAgentEvents where TODO comments exist.","acceptance_criteria":"StoreAgentEvent correctly marshals event.Data to JSON. Retrieve events have Data field properly populated. Integration test verifies round-trip: store complex event data, retrieve it, verify all fields match.","status":"open","priority":0,"issue_type":"bug","created_at":"2025-10-22T20:06:50.521618-07:00","updated_at":"2025-10-22T20:06:50.521618-07:00","dependencies":[{"issue_id":"vc-48","depends_on_id":"vc-37","type":"blocks","created_at":"2025-10-22T20:07:07.488221-07:00","created_by":"daemon"}]}
{"id":"vc-49","title":"Fix ClaimIssue race condition - check all active execution states","description":"ClaimIssue() only checks for state='claimed' before allowing a claim. But if an executor has already transitioned to 'executing', 'analyzing', 'gates', or 'committing', those are ALSO active claims that should block claiming. This allows two executors to claim the same issue (race condition).","design":"In executor.go:142-146, change WHERE clause from 'state = \"claimed\"' to 'state IN (\"claimed\", \"assessing\", \"executing\", \"analyzing\", \"gates\", \"committing\")'. This prevents claiming if issue is in ANY active execution state, not just initial claim state.","acceptance_criteria":"Two concurrent ClaimIssue calls return error on second claim even if first executor has transitioned beyond 'claimed'. Integration test: claim issue, transition to 'executing', attempt second claim -\u003e should fail.","status":"open","priority":0,"issue_type":"bug","created_at":"2025-10-22T20:06:52.398418-07:00","updated_at":"2025-10-22T20:06:52.398418-07:00","dependencies":[{"issue_id":"vc-49","depends_on_id":"vc-37","type":"blocks","created_at":"2025-10-22T20:07:07.498928-07:00","created_by":"daemon"}]}
{"id":"vc-5","title":"FOREIGN KEY constraint failed when cleaning up stale bd-1 instance","description":"During dogfooding run #12, the cleanup routine failed with 'FOREIGN KEY constraint failed' when trying to add release comment for issue bd-1. This happened because bd-1 was deleted from the database but there were still references to it (events, dependencies, or executor instances). The cleanup code tried to add a comment to the non-existent issue.","design":"Root cause: bd-1 was manually deleted from database to clean up phantom issue, but executor instances or events still referenced it. When cleanup routine tried to release bd-1, it failed on FOREIGN KEY constraint. Solution: Before releasing an issue, check if it exists in the database. If not, just clean up the executor instance without trying to add comments. Alternative: Use ON DELETE CASCADE properly so deleting an issue cleans up all references.","acceptance_criteria":"Cleanup routine handles deleted issues gracefully. No FOREIGN KEY errors when releasing stale instances for deleted issues.","notes":"Dogfooding run #13: Quality gates failed (test/lint). Same FOREIGN KEY error occurred during cleanup, proving fix was discarded without GitOps.","status":"blocked","priority":1,"issue_type":"bug","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.131135-07:00"}
{"id":"vc-50","title":"Fix Mission schema mismatch - vc_mission_state missing 7 fields","description":"The vc_mission_state table only stores: sandbox_path, branch_name, iteration_count, gates_status. But types.Mission has 7 additional fields: Goal, Context, PhaseCount, CurrentPhase, ApprovalRequired, ApprovedAt, ApprovedBy. GetMission() returns Mission objects with these fields zero-valued/nil, causing bugs when mission workflow tries to use them.","design":"Add individual columns to vc_mission_state (not JSON metadata blob to avoid polluting git history with unstructured data). New columns:\n- goal TEXT NOT NULL (high-level mission goal)\n- context TEXT (additional planning context)\n- phase_count INTEGER DEFAULT 0 (number of phases in plan)\n- current_phase INTEGER DEFAULT 0 (current phase being executed, 0-indexed)\n- approval_required BOOLEAN DEFAULT FALSE (requires human approval before execution)\n- approved_at DATETIME (when plan was approved)\n- approved_by TEXT (who approved the plan)\n\nUpdate GetMission() in methods.go:46-76 to query all columns. Update CreateIssue() in methods.go:78-104 to insert Mission fields when IssueSubtype=mission. Add validation: current_phase \u003c= phase_count, approved_by required if approved_at set.","acceptance_criteria":"GetMission() returns complete Mission objects with all fields populated. CreateIssue() with IssueSubtype=mission persists all Mission metadata. Mission workflow can use Goal, PhaseCount, ApprovalRequired fields without nil/zero values.","status":"open","priority":0,"issue_type":"bug","created_at":"2025-10-22T20:06:54.431973-07:00","updated_at":"2025-10-22T20:39:00.189765-07:00","dependencies":[{"issue_id":"vc-50","depends_on_id":"vc-37","type":"blocks","created_at":"2025-10-22T20:07:07.50965-07:00","created_by":"daemon"}]}
{"id":"vc-51","title":"Add transaction handling to ClaimIssue - prevent inconsistent state","description":"ClaimIssue() performs two operations: (1) INSERT into vc_issue_execution_state, (2) UpdateIssue to set status='in_progress'. If step 2 fails, database is inconsistent: vc_issue_execution_state says 'claimed' but issues table still says 'open'. No transaction wrapping or rollback on failure.","design":"Two options: (A) Use database transaction with BEGIN/COMMIT/ROLLBACK [PREFERRED]; (B) Add compensating action: if UpdateIssue fails, DELETE FROM vc_issue_execution_state WHERE issue_id = ?. Option A is cleaner but requires transaction support in wrapper. Option B is simpler and doesn't require transaction infrastructure.","acceptance_criteria":"If ClaimIssue fails partway through, database state is consistent (either fully claimed or fully unclaimed, never half-claimed). Integration test: mock UpdateIssue to fail, verify vc_issue_execution_state has no claim record.","status":"open","priority":0,"issue_type":"bug","created_at":"2025-10-22T20:06:55.878728-07:00","updated_at":"2025-10-22T20:06:55.878728-07:00","dependencies":[{"issue_id":"vc-51","depends_on_id":"vc-37","type":"blocks","created_at":"2025-10-22T20:07:07.52085-07:00","created_by":"daemon"}]}
{"id":"vc-52","title":"Implement GetAgentEvents with proper filtering","description":"GetAgentEvents() currently returns 'not yet implemented' error (wrapper.go:185). This is a Storage interface method that will cause crashes if called. Need to implement with proper EventFilter support (filter by issue_id, type, severity, time range).","design":"Implement in wrapper.go:183-186. Build WHERE clause dynamically based on EventFilter fields. Support: IssueID (exact match), Type (exact match), Severity (exact match), StartTime/EndTime (range), Limit (LIMIT clause). Return events ordered by timestamp DESC.","acceptance_criteria":"GetAgentEvents() implements all EventFilter fields correctly. Integration test verifies filtering by each field independently and in combination. No 'not yet implemented' errors.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-22T20:07:48.450468-07:00","updated_at":"2025-10-22T20:07:48.450468-07:00","dependencies":[{"issue_id":"vc-52","depends_on_id":"vc-37","type":"blocks","created_at":"2025-10-22T20:08:07.59978-07:00","created_by":"daemon"}]}
{"id":"vc-53","title":"Fix JSON unmarshaling in GetAgentEventsByIssue and GetRecentAgentEvents","description":"GetAgentEventsByIssue() and GetRecentAgentEvents() have TODO comments at lines 208 and 235 in wrapper.go. They scan dataJSON from database but never unmarshal it to event.Data. All returned events have Data=nil even though database contains JSON. Event data is silently lost on retrieval.","design":"In wrapper.go:208 and wrapper.go:235, add unmarshaling: if dataJSON.Valid \u0026\u0026 dataJSON.String != \"\" { if err := json.Unmarshal([]byte(dataJSON.String), \u0026e.Data); err != nil { return nil, fmt.Errorf(\"failed to unmarshal event data: %w\", err) } }. Need to determine correct type for e.Data field first (interface{} or specific struct).","acceptance_criteria":"GetAgentEventsByIssue and GetRecentAgentEvents return events with Data field populated. Integration test: store event with complex Data object, retrieve it, verify Data matches original.","status":"open","priority":1,"issue_type":"bug","created_at":"2025-10-22T20:07:50.089364-07:00","updated_at":"2025-10-22T20:07:50.089364-07:00","dependencies":[{"issue_id":"vc-53","depends_on_id":"vc-37","type":"blocks","created_at":"2025-10-22T20:08:07.610934-07:00","created_by":"daemon"}]}
{"id":"vc-54","title":"Fix GetDependencyTree recursive children conversion","description":"GetDependencyTree() returns flat list with all Children=nil (methods.go:217). The TODO comment says 'convert children recursively if needed' but it's not implemented. Dependency trees are completely broken - structure is lost.","design":"Two options: (A) Implement recursive conversion to preserve tree structure; (B) Document that GetDependencyTree returns flattened tree with Depth field, and Children should not be used. Check what beads.Storage.GetDependencyTree actually returns. If Beads returns flat list, option B is correct. If Beads returns nested tree, need option A.","acceptance_criteria":"GetDependencyTree either: (A) returns properly nested tree with Children populated recursively, OR (B) documents that it returns flat list and Children is always nil. Either way, behavior matches documentation and Beads semantics.","status":"open","priority":1,"issue_type":"bug","created_at":"2025-10-22T20:07:51.551523-07:00","updated_at":"2025-10-22T20:07:51.551523-07:00","dependencies":[{"issue_id":"vc-54","depends_on_id":"vc-37","type":"blocks","created_at":"2025-10-22T20:08:07.621939-07:00","created_by":"daemon"}]}
{"id":"vc-55","title":"Fix GetBlockedIssues - convert Blockers list","description":"GetBlockedIssues() returns BlockedIssue objects with Blockers=nil (methods.go:284 TODO comment). You can see THAT an issue is blocked but not WHAT it's blocked by. Makes it impossible to diagnose blocking relationships.","design":"In methods.go:280-287, convert bb.Blockers from beadsTypes to vcTypes. Need to check what beads.Storage.GetBlockedIssues returns in BlockedIssue.Blockers field. If it's []string (issue IDs), keep as-is. If it's []*beadsTypes.Issue, convert each one with beadsIssueToVC().","acceptance_criteria":"GetBlockedIssues returns BlockedIssue objects with Blockers field populated. Integration test: create issue A and B, add dependency B blocks A, call GetBlockedIssues, verify A.Blockers contains B.","status":"open","priority":1,"issue_type":"bug","created_at":"2025-10-22T20:07:53.118124-07:00","updated_at":"2025-10-22T20:07:53.118124-07:00","dependencies":[{"issue_id":"vc-55","depends_on_id":"vc-37","type":"blocks","created_at":"2025-10-22T20:08:07.632654-07:00","created_by":"daemon"}]}
{"id":"vc-56","title":"Add explicit Close() method to VCStorage","description":"VCStorage embeds beads.Storage which has Close() method, so calling store.Close() delegates to Beads. This works but is undocumented and fragile - if Beads changes its Close() behavior, VC breaks silently. Need explicit Close() method that documents the delegation pattern.","design":"Add to wrapper.go: func (s *VCStorage) Close() error { // Beads owns the DB connection (s.db is the same underlying connection) // so we just delegate to Beads.Storage.Close() which closes the DB return s.Storage.Close() }. Add integration test that verifies Close() actually closes the database connection.","acceptance_criteria":"VCStorage has explicit Close() method with documentation explaining delegation to Beads. Integration test verifies Close() works and subsequent operations fail with 'database is closed' error.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-22T20:07:55.405457-07:00","updated_at":"2025-10-22T20:07:55.405457-07:00","dependencies":[{"issue_id":"vc-56","depends_on_id":"vc-37","type":"blocks","created_at":"2025-10-22T20:08:07.643097-07:00","created_by":"daemon"}]}
{"id":"vc-57","title":"Add state transition validation to UpdateExecutionState","description":"UpdateExecutionState() (executor.go:220-232) accepts any state transition without validation. Can go from 'completed' back to 'claimed', 'executing' to 'pending', etc. This will cause state machine bugs and make debugging difficult (invalid state history).","design":"Add state transition validation. Valid transitions: pending→claimed, claimed→assessing, assessing→executing, executing→analyzing, analyzing→gates, gates→committing, committing→completed. Also allow: any state→failed (error case). Reject invalid transitions with clear error message. Document the state machine in types/types.go or CLAUDE.md.","acceptance_criteria":"UpdateExecutionState rejects invalid transitions with descriptive error. Integration test verifies all valid transitions work and invalid ones fail. State machine diagram documented.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-22T20:07:58.618227-07:00","updated_at":"2025-10-22T20:07:58.618227-07:00","dependencies":[{"issue_id":"vc-57","depends_on_id":"vc-37","type":"blocks","created_at":"2025-10-22T20:08:07.653375-07:00","created_by":"daemon"}]}
{"id":"vc-58","title":"Add batch GetIssues() method for performance optimization","description":"GetIssue(id) triggers N+1 query problem: one query to Beads for core issue, one query to vc_mission_state for subtype. If you fetch 100 issues, this executes 200 queries. Slow for bulk operations like GetReadyWork or list views.","design":"Add GetIssues(ids []string) ([]*types.Issue, error) method. Use single query to Beads, then single JOIN query or WHERE IN query to fetch all subtypes at once. Return issues in same order as input IDs. Alternative: create VIEW that JOINs issues and vc_mission_state, use that for all queries.","acceptance_criteria":"GetIssues fetches 100 issues in ~2 queries instead of 200. Benchmark shows \u003e10x speedup for bulk fetches. Integration test verifies correctness.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-22T20:08:47.584117-07:00","updated_at":"2025-10-22T20:08:47.584117-07:00","dependencies":[{"issue_id":"vc-58","depends_on_id":"vc-37","type":"blocks","created_at":"2025-10-22T20:09:08.088823-07:00","created_by":"daemon"}]}
{"id":"vc-59","title":"Add pagination to GetExecutionHistory","description":"GetExecutionHistory(issueID) has no LIMIT clause. If an issue has been executed 10,000 times (watchdog retries), this loads all 10,000 rows into memory. Resource leak risk for long-running issues with many retry attempts.","design":"Add pagination parameters: GetExecutionHistory(issueID string, limit int, offset int). Or use cursor-based pagination with 'after' parameter (more efficient). Default limit to 100 if not specified. Document that callers should paginate for issues with many attempts.","acceptance_criteria":"GetExecutionHistory limits results by default. Can fetch large histories in pages without OOM. Integration test with 1000 execution attempts verifies pagination works correctly.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-22T20:08:50.065819-07:00","updated_at":"2025-10-22T20:08:50.065819-07:00","dependencies":[{"issue_id":"vc-59","depends_on_id":"vc-37","type":"blocks","created_at":"2025-10-22T20:09:08.100368-07:00","created_by":"daemon"}]}
{"id":"vc-6","title":"Update mock storage implementations to match storage.Storage interface","description":"The storage.Storage interface has been updated with new methods (CleanupEventsByAge and GetEventCounts), but mock implementations in tests have not been updated accordingly. This causes compilation failures across multiple test files.\n\nAffected files:\n- internal/mission/orchestrator_rollback_test.go\n- internal/mission/orchestrator_test.go\n- internal/ai/supervisor_test.go\n\nRequired actions:\n1. Add CleanupEventsByAge method to MockStorage in mission tests\n2. Add GetEventCounts method to mockStorage in ai tests\n3. Implement stub/mock behavior for these methods\n4. Verify all tests compile and pass","design":"Fix the quality gate failure described above","acceptance_criteria":"Gate passes without errors","status":"blocked","priority":1,"issue_type":"bug","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.131345-07:00","dependencies":[{"issue_id":"vc-6","depends_on_id":"vc-7","type":"blocks","created_at":"2025-10-21T12:17:50.171608-07:00","created_by":"import"}]}
{"id":"vc-60","title":"Add GetMissionByPhase() query for phase navigation","description":"GetMission(id) works if you know the mission ID. But if you have a phase issue, there's no way to navigate to its parent mission. Need to query dependencies for parent-child relationship, which is inefficient and requires multiple queries.","design":"Add GetMissionByPhase(phaseID string) (*types.Mission, error). Query dependencies table for parent-child relationship where phaseID is child, find parent with subtype='mission'. Or store mission_id directly in vc_mission_state for phases (denormalization for performance).","acceptance_criteria":"Given a phase ID, can retrieve parent mission in single query. Integration test: create mission with 3 phases, call GetMissionByPhase on phase 2, verify returns correct mission.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-22T20:08:52.56883-07:00","updated_at":"2025-10-22T20:08:52.56883-07:00","dependencies":[{"issue_id":"vc-60","depends_on_id":"vc-37","type":"blocks","created_at":"2025-10-22T20:09:08.110991-07:00","created_by":"daemon"}]}
{"id":"vc-61","title":"Add comprehensive integration tests for edge cases","description":"Current integration tests (integration_test.go) verify basic happy path: create issue, claim, release. Missing tests for edge cases: NULL handling, empty strings, concurrent operations, error recovery, boundary conditions.","design":"Add test cases: (1) NULL sandbox_path, branch_name, checkpoint_data; (2) Empty title/description (should fail validation); (3) Very long strings (\u003e500 chars); (4) Invalid enum values; (5) Foreign key violations; (6) Constraint violations; (7) Issue doesn't exist in vc_mission_state but exists in issues table (GetIssue should still work).","acceptance_criteria":"Integration test coverage \u003e80%. All edge cases have explicit test cases. CI catches regressions.","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-22T20:08:54.904221-07:00","updated_at":"2025-10-22T20:08:54.904221-07:00","dependencies":[{"issue_id":"vc-61","depends_on_id":"vc-37","type":"blocks","created_at":"2025-10-22T20:09:08.121376-07:00","created_by":"daemon"}]}
{"id":"vc-62","title":"Add transaction rollback tests","description":"No tests verify behavior when multi-step operations fail partway through (ClaimIssue, ReleaseIssueAndReopen). Need tests that mock failure at each step and verify database consistency. Critical for correctness of atomic operations.","design":"Add test cases for ClaimIssue: (1) Mock Beads UpdateIssue to fail, verify vc_issue_execution_state has no claim; (2) Mock INSERT into vc_issue_execution_state to fail, verify no state changes. For ReleaseIssueAndReopen: mock UpdateIssue and AddComment failures. Use test doubles or database fault injection.","acceptance_criteria":"Transaction rollback tests verify database consistency after failures. Tests catch bugs in error handling paths. All multi-step operations have rollback tests.","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-22T20:08:56.679613-07:00","updated_at":"2025-10-22T20:08:56.679613-07:00","dependencies":[{"issue_id":"vc-62","depends_on_id":"vc-37","type":"blocks","created_at":"2025-10-22T20:09:08.131663-07:00","created_by":"daemon"}]}
{"id":"vc-63","title":"Add concurrency tests for ClaimIssue","description":"ClaimIssue has TOCTOU race condition check (executor.go:142-153) but no tests verify it works under concurrent load. Need tests with multiple goroutines attempting to claim same issue simultaneously. Critical for executor correctness when running multiple instances.","design":"Add concurrency test: spawn 10 goroutines that all try to ClaimIssue on same issue ID at same time. Verify exactly one succeeds, 9 fail with 'already claimed' error. Use sync.WaitGroup to coordinate start time. Test with different timing (immediate vs staggered). Also test claim after state transitions (one goroutine claims and transitions to 'executing', another tries to claim).","acceptance_criteria":"Concurrency tests verify only one executor can claim an issue. Race detector (-race flag) passes. Tests run 100 times without failure.","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-22T20:08:58.944686-07:00","updated_at":"2025-10-22T20:08:58.944686-07:00","dependencies":[{"issue_id":"vc-63","depends_on_id":"vc-37","type":"blocks","created_at":"2025-10-22T20:09:08.142532-07:00","created_by":"daemon"}]}
{"id":"vc-7","title":"Fix errcheck and staticcheck lint violations in health package","description":"The health package has several lint violations that need to be addressed:\n\n1. Unchecked error returns for os.RemoveAll in cruft_detector_test.go (lines 70, 131, 179)\n2. Unchecked error return for f.Close in filesize.go (line 256) and filesize_test.go (line 463)\n3. Unchecked error return for os.Remove in registry.go (line 292)\n4. QF1003 staticcheck issue in assessment.go (line 224) - could use tagged switch\n\nThese are pre-existing lint issues unrelated to the storage interface updates but caught during CI.","design":"Fix the quality gate failure described above","acceptance_criteria":"Gate passes without errors","status":"blocked","priority":1,"issue_type":"bug","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.131601-07:00"}
{"id":"vc-8","title":"Polish REPL UX (tab completion, history persistence, Ctrl+C handling)","description":"Final polish: tab completion, persistent history, better error messages, Ctrl+C handling. Makes REPL production-ready.","design":"Add tab completion for commands using readline.PrefixCompleter. Persist history to ~/.vc/repl_history. Intercept Ctrl+C to not exit on first press (require exit command). Add better help text with examples. Improve color scheme for readability. Add welcome banner with quick start guide.","acceptance_criteria":"- Tab completion works for commands\n- Command history persists across sessions\n- Ctrl+C doesn't exit immediately\n- help shows useful examples\n- Welcome banner on startup\n- Clean, professional UX","notes":"REPL UX improvements - could be a VC candidate later, but requires Go readline library knowledge and UX judgment. For now, good candidate for manual/Claude Code work.","status":"open","priority":1,"issue_type":"task","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.131833-07:00"}
{"id":"vc-9","title":"Watchdog: Core monitor and telemetry collection","description":"Create the core watchdog monitor that collects telemetry from the executor event loop and agent executions. This is the foundation for behavioral analysis.","design":"Create internal/watchdog package with Monitor type that:\n- Hooks into executor event loop via callback/observer pattern\n- Collects telemetry: issue execution count, duration, state transitions, event patterns\n- Stores telemetry in memory with sliding window (last N executions)\n- Provides GetTelemetry() API for consumption by analyzer\n- No decision-making logic (pure data collection - ZFC compliant)","acceptance_criteria":"- Monitor collects executor telemetry without blocking event loop\n- Telemetry includes: issue ID, start/end time, state transitions, event counts by type\n- Unit tests demonstrate telemetry collection\n- Integration point in executor event loop (processNextIssue)","notes":"Code review completed and critical issues fixed:\n- Issue 1: Fixed state transition tracking to be conditional on whether AI assessment ran\n- Issue 2: Changed GetTelemetry() from shallow to deep copy to prevent external mutation\n- Added TestMonitor_GetTelemetryDeepCopy test to verify fix\n- All 11 tests passing","status":"blocked","priority":1,"issue_type":"task","created_at":"2025-10-21T12:17:50.127462-07:00","updated_at":"2025-10-22T00:15:23.132058-07:00","dependencies":[{"issue_id":"vc-9","depends_on_id":"vc-6","type":"blocks","created_at":"2025-10-21T12:17:50.190351-07:00","created_by":"import"}]}
